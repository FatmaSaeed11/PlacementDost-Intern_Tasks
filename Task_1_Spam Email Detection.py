# -*- coding: utf-8 -*-
"""Placement Dost task_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NL56fkc-bnzQDIF_-etPiTBwVdnHd7le

Detect Spam Emails

import important libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import string
import nltk


from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix

"""download stopwords for preprocessing"""

nltk.download('stopwords')

"""import dataset"""

dataset=pd.read_csv('/content/spam_ham_dataset.csv')

dataset

"""show data and info about it"""

dataset.text.iloc[5]

dataset.info()

import matplotlib.pyplot as plt
plt.pie(dataset['label'].value_counts(), labels=['ham','spam'],autopct="%0.2f")
plt.show()

"""stemming"""

stemmer=PorterStemmer()

stemmer=PorterStemmer()
corpus=[]
stopwords_set=set(stopwords.words('english'))
for i in range(len(dataset)):
  text=dataset['text'].iloc[i].lower()
  text=text.translate(str.maketrans('','',string.punctuation)).split()
  text=[stemmer.stem(word )for word in text if word not in stopwords_set]
  text=' '.join(text)
  corpus.append(text)

print("email after stemming",corpus[0])

print("email before stemming",dataset.text.iloc[0])

"""convert text data into numbers"""

vectorizer=CountVectorizer()

x=vectorizer.fit_transform(corpus).toarray()
y=dataset.label_num

x[0]

"""train,test split"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

"""build our model"""

model=RandomForestClassifier(n_jobs=-1)
model.fit(x_train,y_train)

model.score(x_test,y_test)

"""prediction "check if mail is spam or not"
"""

email_to_classify=dataset.text.values[14]

email_to_classify

email=email_to_classify.lower().translate(str.maketrans('','',string.punctuation)).split()
email=[stemmer.stem(word) for word in email if word not in stopwords_set]
email=' '.join(email)

email_corpus=[email]
x_email=vectorizer.transform(email_corpus)

x=model.predict(x_email)
predict=x[0]
print("predicted value =",predict)

actual=dataset.label_num.iloc[14]
print("actual value =",actual)

y_pred=model.predict(x_test)

"""Acucuraccy ,precision , Recall ,F1_score"""

accuracy=accuracy_score(y_test,y_pred)
precision=precision_score(y_test,y_pred)
recall=recall_score(y_test,y_pred)
f1=f1_score(y_test,y_pred)

print("Accuracy =",accuracy)
print("precision =",precision)
print("recall =",recall)
print("f1 score =",f1)

"""Confusion Matrix"""

conf_matrix = confusion_matrix(y_pred, y_test)
sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='Blues',cbar=False)
plt.xlabel('predicted Label')
plt.ylabel('Actual Label')
plt.title('Confusion Matrix')

plt.show()